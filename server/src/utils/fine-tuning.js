/**
 * FINE-TUNING UTILITY
 * 
 * Diese Datei enthÃ¤lt alle Funktionen fÃ¼r Fine-Tuning von OpenAI-Modellen.
 * - Sammelt perfekte Beispiele aus Feedback und Training-Daten
 * - Konvertiert zu JSONL-Format fÃ¼r OpenAI
 * - LÃ¤dt Daten hoch und startet Fine-Tuning
 * - PrÃ¼ft Status und verwaltet Modelle
 */

const fs = require('fs');
const path = require('path');
const { getClient } = require('../openaiClient');
const { getGitHubClient, getRepoInfo } = require('./github');

// ğŸš¨ NEU: Helper-Funktion zum Extrahieren der letzten 6 Nachrichten aus conversationHistory
function extractRecentMessages(conversationHistory) {
  if (!conversationHistory || conversationHistory.trim().length === 0) {
    return [];
  }
  
  const historyLines = conversationHistory.split('\n').filter(line => line.trim().length > 0);
  const messages = [];
  
  // Parse alle Nachrichten
  historyLines.forEach(line => {
    const trimmed = line.trim();
    const lower = trimmed.toLowerCase();
    
    // Erkenne Moderator-Nachrichten (Fake/Du/Moderator/Assistant)
    if (lower.includes('fake:') || lower.includes('du:') || lower.includes('moderator:') || lower.includes('assistant:')) {
      const match = trimmed.match(/(?:fake|du|moderator|assistant):\s*(.+)/i);
      if (match && match[1]) {
        messages.push({ type: 'moderator', text: match[1].trim() });
      }
    }
    // Erkenne Kunden-Nachrichten
    else if (lower.includes('kunde:') || lower.includes('customer:') || lower.includes('user:')) {
      const match = trimmed.match(/(?:kunde|customer|user):\s*(.+)/i);
      if (match && match[1]) {
        messages.push({ type: 'customer', text: match[1].trim() });
      }
    }
  });
  
  // Nimm die letzten 6 Nachrichten (chronologisch - Ã¤lteste zuerst, neueste zuletzt)
  return messages.slice(-6);
}

// Lade Feedback-Daten
async function getFeedbackData() {
  const githubClient = getGitHubClient();
  if (githubClient) {
    try {
      const repo = getRepoInfo();
      const possiblePaths = [
        'server/src/config/feedback.json',
        'src/config/feedback.json',
        'config/feedback.json',
        'server/config/feedback.json'
      ];
      
      for (const filePath of possiblePaths) {
        try {
          const response = await githubClient.repos.getContent({
            owner: repo.owner,
            repo: repo.repo,
            path: filePath,
            ref: repo.branch
          });
          if (response.data && response.data.content) {
            const content = Buffer.from(response.data.content, 'base64').toString('utf8');
            return JSON.parse(content);
          }
        } catch (err) {
          if (err.status !== 404) throw err;
        }
      }
    } catch (err) {
      if (err.status !== 404) {
        console.error('âš ï¸ Fehler beim Laden der Feedback-Daten von GitHub:', err.message);
      }
    }
  }
  
  // Fallback: Lade von lokaler Datei
  const feedbackPath = path.join(__dirname, '../../config/feedback.json');
  try {
    if (fs.existsSync(feedbackPath)) {
      const data = fs.readFileSync(feedbackPath, 'utf8');
      return JSON.parse(data);
    }
  } catch (err) {
    console.error('Fehler beim Laden der Feedback-Daten:', err);
  }
  return { feedbacks: [] };
}

// Lade Training-Daten
async function getTrainingData() {
  const githubClient = getGitHubClient();
  if (githubClient) {
    try {
      const repo = getRepoInfo();
      const possiblePaths = [
        'server/src/config/training-data.json',
        'src/config/training-data.json',
        'config/training-data.json',
        'server/config/training-data.json'
      ];
      
      for (const filePath of possiblePaths) {
        try {
          const response = await githubClient.repos.getContent({
            owner: repo.owner,
            repo: repo.repo,
            path: filePath,
            ref: repo.branch
          });
          if (response.data && response.data.content) {
            const content = Buffer.from(response.data.content, 'base64').toString('utf8');
            return JSON.parse(content);
          }
        } catch (err) {
          if (err.status !== 404) throw err;
        }
      }
    } catch (err) {
      if (err.status !== 404) {
        console.error('âš ï¸ Fehler beim Laden der Training-Daten von GitHub:', err.message);
      }
    }
  }
  
  // Fallback: Lade von lokaler Datei
  const trainingPath = path.join(__dirname, '../../config/training-data.json');
  try {
    if (fs.existsSync(trainingPath)) {
      const data = fs.readFileSync(trainingPath, 'utf8');
      return JSON.parse(data);
    }
  } catch (err) {
    console.error('Fehler beim Laden der Training-Daten:', err);
  }
  return { conversations: [], asaExamples: [] };
}

// Lade Fine-Tuning-Config
async function getFineTuningConfig() {
  const configPath = path.join(__dirname, '../../config/fine-tuning-config.json');
  try {
    if (fs.existsSync(configPath)) {
      const data = fs.readFileSync(configPath, 'utf8');
      return JSON.parse(data);
    }
  } catch (err) {
    console.error('Fehler beim Laden der Fine-Tuning-Config:', err);
  }
  
  // Standard-Config
  return {
    modelId: null,
    lastTrained: null,
    trainingExamplesCount: 0,
    nextRetrainAt: 50,
    currentJobId: null,
    status: 'idle',
    systemPrompt: `Du bist ein Chat-Moderator auf einer Dating-Plattform. Du verwaltest verschiedene Fake-Profile und antwortest als diese Profile auf Kunden-Nachrichten.

HARTE REGELN (NIEMALS verletzen):
1. KEINE Treffen zustimmen (immer ablehnen, hÃ¶flich ausweichen)
2. KEINE verbotenen WÃ¶rter verwenden (siehe Liste im User-Prompt)
3. PrÃ¤gnant und natÃ¼rlich: 120-250 Zeichen (bei Erstnachrichten 150-300 Zeichen). Keine unnÃ¶tigen FÃ¼llsÃ¤tze oder ErklÃ¤rungen (z.B. "beschÃ¤ftigt sein" ohne Grund).
4. NatÃ¼rlich und authentisch (nicht nach KI klingen)

STIL:
- Sei warmherzig, interessiert, menschlich
- Stelle Fragen, um GesprÃ¤ch am Laufen zu halten
- Gehe auf alle Anfragen/Themen ein
- Zeige Eigeninitiative (nenne eigene Vorlieben/Interessen, dann frage)
- Sei prÃ¤gnant - keine unnÃ¶tigen Details oder ErklÃ¤rungen`
  };
}

// Speichere Fine-Tuning-Config
async function saveFineTuningConfig(config) {
  const configPath = path.join(__dirname, '../../config/fine-tuning-config.json');
  const configDir = path.dirname(configPath);
  if (!fs.existsSync(configDir)) {
    fs.mkdirSync(configDir, { recursive: true });
  }
  fs.writeFileSync(configPath, JSON.stringify(config, null, 2));
}

// Sammle alle perfekten Beispiele aus Feedback und Training-Daten
// Gibt auch ausgeschlossene Beispiele zurÃ¼ck fÃ¼r Debugging/Bearbeitung
async function collectPerfectExamples(includeExcluded = false) {
  const examples = [];
  const seen = new Set(); // FÃ¼r Deduplizierung
  
  // Debug-ZÃ¤hler und ausgeschlossene Beispiele
  let skippedTooShort = { feedback_good: 0, feedback_edited: 0, training: 0, asa: 0 };
  let skippedDuplicate = { feedback_good: 0, feedback_edited: 0, training: 0, asa: 0 };
  let skippedNoMessage = { feedback_good: 0, feedback_edited: 0, training: 0, asa: 0 };
  const excludedExamples = {
    tooShort: [],
    duplicate: [],
    noMessage: []
  };
  
  // 1. Sammle aus Feedback-Daten
  const feedbackData = await getFeedbackData();
  if (feedbackData && feedbackData.feedbacks) {
    console.log(`ğŸ“Š PrÃ¼fe ${feedbackData.feedbacks.length} Feedbacks...`);
    feedbackData.feedbacks.forEach(feedback => {
      // "good" Feedbacks: aiResponse ist gut
      if (feedback.status === 'good' && feedback.aiResponse) {
        const key = `${feedback.customerMessage || ''}|${feedback.aiResponse}`;
        if (seen.has(key)) {
          skippedDuplicate.feedback_good++;
          if (includeExcluded) {
            excludedExamples.duplicate.push({
              source: 'feedback_good',
              customerMessage: feedback.customerMessage || (feedback.isASA ? "ASA Reaktivierung" : ""),
              moderatorResponse: feedback.aiResponse,
              reason: 'duplicate',
              length: feedback.aiResponse.length,
              feedbackId: feedback.id
            });
          }
          return;
        }
        if (feedback.aiResponse.length < 120) {
          skippedTooShort.feedback_good++;
          if (includeExcluded) {
            excludedExamples.tooShort.push({
              source: 'feedback_good',
              customerMessage: feedback.customerMessage || (feedback.isASA ? "ASA Reaktivierung" : ""),
              moderatorResponse: feedback.aiResponse,
              reason: 'too_short',
              length: feedback.aiResponse.length,
              feedbackId: feedback.id
            });
          }
          return;
        }
        seen.add(key);
        examples.push({
          customerMessage: feedback.customerMessage || (feedback.isASA ? "ASA Reaktivierung" : ""),
          moderatorResponse: feedback.aiResponse,
          situation: feedback.situation || feedback.context?.detectedSituations?.[0] || 'allgemein',
          source: 'feedback_good',
          feedbackId: feedback.id,
          // ğŸš¨ NEU: Extrahiere letzte 6 Nachrichten aus conversationHistory (wenn vorhanden)
          recentMessages: extractRecentMessages(feedback.conversationHistory || feedback.context?.conversationHistory || '')
        });
      } else if (feedback.status === 'good') {
        skippedNoMessage.feedback_good++;
        if (includeExcluded) {
          excludedExamples.noMessage.push({
            source: 'feedback_good',
            customerMessage: feedback.customerMessage || (feedback.isASA ? "ASA Reaktivierung" : ""),
            moderatorResponse: null,
            reason: 'no_message',
            feedbackId: feedback.id
          });
        }
      }
      
      // "edited" Feedbacks: editedResponse ist gut (bearbeitete Version)
      if (feedback.status === 'edited' && feedback.editedResponse) {
        const key = `${feedback.customerMessage || ''}|${feedback.editedResponse}`;
        if (seen.has(key)) {
          skippedDuplicate.feedback_edited++;
          if (includeExcluded) {
            excludedExamples.duplicate.push({
              source: 'feedback_edited',
              customerMessage: feedback.customerMessage || (feedback.isASA ? "ASA Reaktivierung" : ""),
              moderatorResponse: feedback.editedResponse,
              reason: 'duplicate',
              length: feedback.editedResponse.length,
              feedbackId: feedback.id
            });
          }
          return;
        }
        if (feedback.editedResponse.length < 120) {
          skippedTooShort.feedback_edited++;
          if (includeExcluded) {
            excludedExamples.tooShort.push({
              source: 'feedback_edited',
              customerMessage: feedback.customerMessage || (feedback.isASA ? "ASA Reaktivierung" : ""),
              moderatorResponse: feedback.editedResponse,
              reason: 'too_short',
              length: feedback.editedResponse.length,
              feedbackId: feedback.id
            });
          }
          return;
        }
        seen.add(key);
        examples.push({
          customerMessage: feedback.customerMessage || (feedback.isASA ? "ASA Reaktivierung" : ""),
          moderatorResponse: feedback.editedResponse,
          situation: feedback.situation || feedback.context?.detectedSituations?.[0] || 'allgemein',
          source: 'feedback_edited',
          feedbackId: feedback.id,
          // ğŸš¨ NEU: Extrahiere letzte 6 Nachrichten aus conversationHistory (wenn vorhanden)
          recentMessages: extractRecentMessages(feedback.conversationHistory || feedback.context?.conversationHistory || '')
        });
      } else if (feedback.status === 'edited') {
        skippedNoMessage.feedback_edited++;
        if (includeExcluded) {
          excludedExamples.noMessage.push({
            source: 'feedback_edited',
            customerMessage: feedback.customerMessage || (feedback.isASA ? "ASA Reaktivierung" : ""),
            moderatorResponse: null,
            reason: 'no_message',
            feedbackId: feedback.id
          });
        }
      }
    });
  }
  
  // 2. Sammle aus Training-Daten (nur positive Beispiele)
  const trainingData = await getTrainingData();
  
  // 2.1 Aus conversations
  if (trainingData && trainingData.conversations) {
    console.log(`ğŸ“Š PrÃ¼fe ${trainingData.conversations.length} Training-GesprÃ¤che...`);
    trainingData.conversations.forEach((conv, index) => {
      // Nur positive Beispiele (nicht isNegativeExample)
      if (conv.isNegativeExample) return;
      if (!conv.moderatorResponse) {
        skippedNoMessage.training++;
        if (includeExcluded) {
          excludedExamples.noMessage.push({
            source: 'training_data',
            customerMessage: conv.customerMessage || "",
            moderatorResponse: null,
            reason: 'no_message',
            index: index
          });
        }
        return;
      }
      if (conv.moderatorResponse.length < 120) {
        skippedTooShort.training++;
        if (includeExcluded) {
          excludedExamples.tooShort.push({
            source: 'training_data',
            customerMessage: conv.customerMessage || "",
            moderatorResponse: conv.moderatorResponse,
            reason: 'too_short',
            length: conv.moderatorResponse.length,
            index: index
          });
        }
        return;
      }
      const key = `${conv.customerMessage || ''}|${conv.moderatorResponse}`;
      if (seen.has(key)) {
        skippedDuplicate.training++;
        if (includeExcluded) {
          excludedExamples.duplicate.push({
            source: 'training_data',
            customerMessage: conv.customerMessage || "",
            moderatorResponse: conv.moderatorResponse,
            reason: 'duplicate',
            length: conv.moderatorResponse.length,
            index: index
          });
        }
        return;
      }
      seen.add(key);
      examples.push({
        customerMessage: conv.customerMessage || "",
        moderatorResponse: conv.moderatorResponse,
        situation: conv.situation || 'allgemein',
        source: 'training_data',
        // ğŸš¨ NEU: Extrahiere letzte 6 Nachrichten aus conversationHistory (wenn vorhanden)
        recentMessages: extractRecentMessages(conv.conversationHistory || conv.previousMessage || '')
      });
    });
  }
  
  // 2.2 Aus asaExamples
  if (trainingData && trainingData.asaExamples) {
    console.log(`ğŸ“Š PrÃ¼fe ${trainingData.asaExamples.length} ASA-Beispiele...`);
    trainingData.asaExamples.forEach((asa, index) => {
      const asaMessage = asa.asaMessage || asa.moderatorResponse;
      if (!asaMessage) {
        skippedNoMessage.asa++;
        if (includeExcluded) {
          excludedExamples.noMessage.push({
            source: 'asa_training_data',
            customerMessage: "ASA Reaktivierung",
            moderatorResponse: null,
            reason: 'no_message',
            index: index,
            asaData: asa
          });
        }
        console.log(`âš ï¸ ASA-Beispiel ohne Nachricht:`, asa);
        return;
      }
      if (asaMessage.length < 120) {
        skippedTooShort.asa++;
        if (includeExcluded) {
          excludedExamples.tooShort.push({
            source: 'asa_training_data',
            customerMessage: "ASA Reaktivierung",
            moderatorResponse: asaMessage,
            reason: 'too_short',
            length: asaMessage.length,
            index: index
          });
        }
        console.log(`âš ï¸ ASA-Beispiel zu kurz (${asaMessage.length} Zeichen):`, asaMessage.substring(0, 100));
        return;
      }
      const key = `ASA Reaktivierung|${asaMessage}`;
      if (seen.has(key)) {
        skippedDuplicate.asa++;
        if (includeExcluded) {
          excludedExamples.duplicate.push({
            source: 'asa_training_data',
            customerMessage: "ASA Reaktivierung",
            moderatorResponse: asaMessage,
            reason: 'duplicate',
            length: asaMessage.length,
            index: index
          });
        }
        return;
      }
      seen.add(key);
      examples.push({
        customerMessage: "ASA Reaktivierung",
        moderatorResponse: asaMessage,
        situation: asa.situation || 'ASA Reaktivierung',
        source: 'asa_training_data'
      });
    });
  }
  
  console.log(`âœ… ${examples.length} perfekte Beispiele gesammelt:`);
  console.log(`   - Feedback (good): ${examples.filter(e => e.source === 'feedback_good').length} (Ã¼bersprungen: ${skippedTooShort.feedback_good} zu kurz, ${skippedDuplicate.feedback_good} dupliziert, ${skippedNoMessage.feedback_good} ohne Nachricht)`);
  console.log(`   - Feedback (edited): ${examples.filter(e => e.source === 'feedback_edited').length} (Ã¼bersprungen: ${skippedTooShort.feedback_edited} zu kurz, ${skippedDuplicate.feedback_edited} dupliziert, ${skippedNoMessage.feedback_edited} ohne Nachricht)`);
  console.log(`   - Training-Daten: ${examples.filter(e => e.source === 'training_data').length} (Ã¼bersprungen: ${skippedTooShort.training} zu kurz, ${skippedDuplicate.training} dupliziert, ${skippedNoMessage.training} ohne Nachricht)`);
  console.log(`   - ASA-Beispiele: ${examples.filter(e => e.source === 'asa_training_data').length} (Ã¼bersprungen: ${skippedTooShort.asa} zu kurz, ${skippedDuplicate.asa} dupliziert, ${skippedNoMessage.asa} ohne Nachricht)`);
  
  if (includeExcluded) {
    return {
      examples,
      excluded: excludedExamples,
      stats: {
        total: examples.length,
        excluded: {
          tooShort: excludedExamples.tooShort.length,
          duplicate: excludedExamples.duplicate.length,
          noMessage: excludedExamples.noMessage.length,
          total: excludedExamples.tooShort.length + excludedExamples.duplicate.length + excludedExamples.noMessage.length
        }
      }
    };
  }
  
  return examples;
}

// PrÃ¼fe Beispiel mit OpenAI Moderation API
async function checkModeration(text) {
  const client = getClient();
  if (!client) {
    return { flagged: false, categories: {} };
  }
  
  try {
    const moderation = await client.moderations.create({
      input: text
    });
    
    const result = moderation.results[0];
    return {
      flagged: result.flagged,
      categories: result.categories,
      categoryScores: result.category_scores
    };
  } catch (err) {
    console.error('âš ï¸ Fehler bei Moderation-Check:', err.message);
    // Bei Fehler: erlaube das Beispiel (besser als alles zu blockieren)
    return { flagged: false, categories: {} };
  }
}

// Filtere Beispiele mit Moderation API
// WICHTIG: Filtert nur sehr problematische Kategorien (Gewalt, Selbstverletzung, etc.)
// "Sexual" wird NICHT gefiltert, da das fÃ¼r Chat-Moderation normal ist
async function filterWithModeration(examples) {
  console.log(`ğŸ” PrÃ¼fe ${examples.length} Beispiele mit OpenAI Moderation API...`);
  
  // Nur diese Kategorien werden wirklich gefiltert (sehr problematisch):
  const CRITICAL_CATEGORIES = [
    'violence',           // Gewalt
    'violence/graphic',   // Grafische Gewalt
    'self-harm',          // Selbstverletzung
    'self-harm/intent',   // Selbstverletzungsabsicht
    'self-harm/instructions', // Anleitungen zu Selbstverletzung
    'illegal',            // Illegale AktivitÃ¤ten
    'hate',               // Hassrede
    'hate/threatening',   // Bedrohende Hassrede
    'harassment/threatening' // Bedrohende BelÃ¤stigung
  ];
  
  // Diese Kategorien werden NUR gewarnt, aber nicht gefiltert:
  const WARNING_CATEGORIES = [
    'harassment'          // BelÃ¤stigung (wird nur gewarnt)
  ];
  
  // ğŸš¨ NEU: FÃ¼r Fine-Tuning filtern wir "sexual" heraus (fÃ¼r Prompt verwenden wir sie trotzdem)
  // Diese Kategorien werden fÃ¼r Fine-Tuning gefiltert, aber fÃ¼r Prompt verwendet:
  const SEXUAL_CATEGORIES = [
    'sexual',             // Sexueller Inhalt (wird fÃ¼r Fine-Tuning gefiltert, aber fÃ¼r Prompt verwendet)
    'sexual/minors'       // Sexueller Inhalt mit MinderjÃ¤hrigen (wird trotzdem gefiltert!)
  ];
  
  const safeExamples = [];
  const flaggedExamples = [];
  const warningExamples = [];
  
  for (let i = 0; i < examples.length; i++) {
    const example = examples[i];
    
    // PrÃ¼fe sowohl Kunden-Nachricht als auch Moderator-Antwort
    const customerText = example.customerMessage || '';
    const moderatorText = example.moderatorResponse || '';
    const combinedText = `${customerText} ${moderatorText}`.trim();
    
    if (!combinedText) {
      // Leere Beispiele Ã¼berspringen
      flaggedExamples.push({
        ...example,
        reason: 'empty',
        flaggedCategories: []
      });
      continue;
    }
    
    // PrÃ¼fe mit Moderation API
    const moderation = await checkModeration(combinedText);
    
    // ğŸš¨ WICHTIG: OpenAI prÃ¼ft strenger als unsere API!
    // Wir mÃ¼ssen auch auf niedrigere Scores prÃ¼fen, nicht nur auf flagged === true
    const categoryScores = moderation.categoryScores || {};
    const categories = moderation.categories || {};
    
    // Finde welche Kategorien geflaggt wurden (flagged === true)
    const flaggedCategories = Object.keys(categories).filter(
      cat => categories[cat] === true
    );
    
    // ğŸš¨ NEU: PrÃ¼fe auch auf Scores (OpenAI filtert auch bei niedrigeren Scores!)
    // ğŸš¨ WICHTIG: OpenAI's interne PrÃ¼fung ist VIEL strenger als die Moderation API!
    // ABER: Die Moderation API markiert fÃ¤lschlicherweise normale Inhalte als "sexual/minors"
    const sexualScore = categoryScores.sexual || 0;
    const sexualMinorsScore = categoryScores['sexual/minors'] || 0;
    
    // ğŸš¨ KRITISCH: OpenAI lehnt Fine-Tuning mit sexuellen Inhalten KOMPLETT ab!
    // LÃ¶sung: Fine-Tuning NUR mit harmlosen Beispielen (OHNE sexuelle Inhalte)
    // Sexuelle Inhalte werden weiterhin im PROMPT verwendet (Hybrid-Ansatz)
    // Wir filtern ALLE sexuellen Inhalte fÃ¼r Fine-Tuning heraus (auch bei niedrigsten Scores)
    const SEXUAL_THRESHOLD = 0.0; // ğŸš¨ ALLES mit sexual score > 0.0 wird gefiltert fÃ¼r Fine-Tuning
    const hasSexualByScore = sexualScore > SEXUAL_THRESHOLD; // Filtert ALLE sexuellen Inhalte
    const hasSexualMinorsByScore = sexualMinorsScore > 0.0; // Filtert ALLE sexual/minors
    
    // ğŸš¨ WICHTIG: Auch harmlose WÃ¶rter wie "kuss" kÃ¶nnen niedrige sexual Scores haben
    // ABER: OpenAI lehnt auch diese ab, wenn zu viele davon vorhanden sind
    // LÃ¶sung: Wir filtern ALLES mit sexual score > 0.0 heraus
    // Die harmlosen Beispiele (ohne sexual score) bleiben erhalten
    
    // PrÃ¼fe ob kritische Kategorien dabei sind
    const hasCritical = flaggedCategories.some(cat => CRITICAL_CATEGORIES.includes(cat));
    // ğŸš¨ KRITISCH: Filtere ALLE sexuellen Inhalte fÃ¼r Fine-Tuning (OpenAI lehnt sie ab!)
    const hasSexualMinors = flaggedCategories.includes('sexual/minors') || hasSexualMinorsByScore;
    const hasSexual = flaggedCategories.includes('sexual') || hasSexualByScore; // Filtert ALLE sexuellen Inhalte
    
    if (hasCritical || hasSexualMinors) {
      // KRITISCH: Filtere diese Beispiele heraus
      flaggedExamples.push({
        ...example,
        reason: 'moderation_critical',
        flaggedCategories: [...flaggedCategories, ...(hasSexualMinorsByScore ? ['sexual/minors (score)'] : [])],
        categoryScores: moderation.categoryScores
      });
      
      console.log(`âŒ Beispiel ${i + 1}/${examples.length} GEFILTERT (kritisch): ${[...flaggedCategories, ...(hasSexualMinorsByScore ? ['sexual/minors (score)'] : [])].join(', ')}`);
    } else if (hasSexual) {
      // ğŸš¨ NEU: Sexuelle Inhalte fÃ¼r Fine-Tuning filtern (aber fÃ¼r Prompt verwenden)
      // WICHTIG: Auch bei niedrigeren Scores filtern, da OpenAI strenger prÃ¼ft!
      flaggedExamples.push({
        ...example,
        reason: 'moderation_sexual', // Spezieller Grund fÃ¼r sexuelle Inhalte
        flaggedCategories: [...flaggedCategories, ...(hasSexualByScore && !flaggedCategories.includes('sexual') ? ['sexual (score)'] : [])],
        categoryScores: moderation.categoryScores,
        sexualScore: sexualScore // FÃ¼r Debugging
      });
      
      console.log(`âš ï¸ Beispiel ${i + 1}/${examples.length} GEFILTERT (sexuell, Score: ${sexualScore.toFixed(3)}, fÃ¼r Fine-Tuning): ${[...flaggedCategories, ...(hasSexualByScore && !flaggedCategories.includes('sexual') ? ['sexual (score)'] : [])].join(', ')}`);
    } else if (moderation.flagged) {
      // NUR WARNUNG: Behalte diese Beispiele, aber warne
      warningExamples.push({
        ...example,
        reason: 'moderation_warning',
        flaggedCategories,
        categoryScores: moderation.categoryScores
      });
      
      safeExamples.push(example); // Trotzdem verwenden
      console.log(`âš ï¸ Beispiel ${i + 1}/${examples.length} WARNUNG (aber verwendet): ${flaggedCategories.join(', ')}`);
    } else {
      safeExamples.push(example);
    }
    
    // Zeige Fortschritt alle 50 Beispiele
    if ((i + 1) % 50 === 0) {
      console.log(`âœ… ${i + 1}/${examples.length} Beispiele geprÃ¼ft, ${safeExamples.length} sicher, ${flaggedExamples.length} gefiltert, ${warningExamples.length} Warnungen`);
    }
  }
  
  console.log(`âœ… Moderation-Check abgeschlossen: ${safeExamples.length} sicher, ${flaggedExamples.length} gefiltert (kritisch), ${warningExamples.length} Warnungen`);
  
  return {
    safe: safeExamples,
    flagged: flaggedExamples,
    warnings: warningExamples
  };
}

// ğŸš¨ğŸš¨ğŸš¨ ÃœBERARBEITET: Konvertiere Beispiele zu JSONL-Format - GENAU wie im aktuellen Inference! ğŸš¨ğŸš¨ğŸš¨
// Format: System-Prompt (mit Situationen) + User-Prompt (einfach: "Kunde: '...' Antworte...") + Assistant
function convertToJSONL(examples, systemPrompt, rules = null) {
  const jsonlLines = [];
  
  examples.forEach(example => {
    // ğŸš¨ğŸš¨ğŸš¨ KRITISCH: User-Prompt GENAU wie im aktuellen Inference-Format!
    // KEINE Meta-Informationen mehr (LÃ¤nge, Typ, Fragen, etc.) - das hat nicht funktioniert!
    // Format: "Kunde: '...' Antworte als Chat-Moderator."
    // Mit Kontext: Letzte 6 Nachrichten (Du: '...' Kunde: '...' etc.) dann Kunde: '...' Antworte als Chat-Moderator.
    
    let userContent = '';
    
    // ğŸš¨ NEU: Wenn letzte 6 Nachrichten vorhanden (fÃ¼r laufende GesprÃ¤che)
    // Format: "Du: '[Nachricht 1]' Kunde: '[Nachricht 2]' Du: '[Nachricht 3]' ... Kunde: '[letzte Nachricht]'"
    if (example.recentMessages && example.recentMessages.length > 0) {
      // Nimm die letzten 6 Nachrichten (chronologisch - Ã¤lteste zuerst, neueste zuletzt)
      const recentMsgs = example.recentMessages.slice(-6);
      recentMsgs.forEach((msg) => {
        const role = msg.type === 'moderator' ? 'Du' : 'Kunde';
        userContent += `${role}: "${msg.text.substring(0, 200)}${msg.text.length > 200 ? '...' : ''}"\n`;
      });
    }
    
    // ğŸš¨ NEU: Einfaches Format wie im Inference
    userContent += `Kunde: "${example.customerMessage}"\n\nAntworte als Chat-Moderator.`;
    
    // ğŸš¨ ENTFERNT: Meta-Informationen (LÃ¤nge, Typ, Fragen, etc.) - nicht mehr nÃ¶tig!
    // ğŸš¨ ENTFERNT: Situation im User-Prompt - steht bereits im System-Prompt!
    // ğŸš¨ ENTFERNT: Verbotene WÃ¶rter im User-Prompt - stehen bereits im System-Prompt!
    
    // ğŸš¨ğŸš¨ğŸš¨ KRITISCH: System-Prompt muss Situationen enthalten (wenn vorhanden)!
    let finalSystemPrompt = systemPrompt;
    
    // Wenn Situation vorhanden und nicht "allgemein", fÃ¼ge Situation-Regeln zum System-Prompt hinzu
    if (example.situation && example.situation !== 'allgemein' && rules && rules.situationalResponses) {
      const situationRules = rules.situationalResponses[example.situation];
      if (situationRules) {
        // FÃ¼ge Situation-Regeln zum System-Prompt hinzu (wie im aktuellen Inference)
        finalSystemPrompt += `\n\nğŸš¨ğŸš¨ğŸš¨ SITUATION: ${example.situation} ğŸš¨ğŸš¨ğŸš¨\n${situationRules}\n\nğŸš¨ KRITISCH: Diese Situation hat HÃ–CHSTE PRIORITÃ„T! Reagiere genau wie oben beschrieben!`;
      }
    }
    
    // Erstelle messages-Array
    const messages = [
      {
        role: "system",
        content: finalSystemPrompt
      },
      {
        role: "user",
        content: userContent
      },
      {
        role: "assistant",
        content: example.moderatorResponse
      }
    ];
    
    // Konvertiere zu JSONL (eine Zeile pro Beispiel)
    jsonlLines.push(JSON.stringify({ messages }));
  });
  
  return jsonlLines.join('\n');
}

// Lade Daten zu OpenAI hoch
async function uploadToOpenAI(jsonlData) {
  const client = getClient();
  if (!client) {
    throw new Error('OpenAI Client nicht verfÃ¼gbar');
  }
  
  // Erstelle temporÃ¤re Datei
  const tempPath = path.join(__dirname, '../../config/temp-training-data.jsonl');
  fs.writeFileSync(tempPath, jsonlData);
  
  try {
    // Lade Datei zu OpenAI hoch
    console.log('ğŸ“¤ Lade JSONL-Datei zu OpenAI hoch...');
    const file = await client.files.create({
      file: fs.createReadStream(tempPath),
      purpose: 'fine-tune'
    });
    
    console.log(`âœ… Daten zu OpenAI hochgeladen: File-ID ${file.id}`);
    
    // ğŸš¨ NEU: Warte kurz und prÃ¼fe ob die Datei validiert wurde
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    try {
      const fileStatus = await client.files.retrieve(file.id);
      console.log(`ğŸ“‹ File-Status: ${fileStatus.status || 'unknown'}`);
      if (fileStatus.status === 'error') {
        throw new Error(`Datei-Validierung fehlgeschlagen: ${fileStatus.error || 'Unbekannter Fehler'}`);
      }
    } catch (err) {
      console.warn('âš ï¸ Konnte File-Status nicht prÃ¼fen:', err.message);
    }
    
    return file.id;
  } catch (err) {
    console.error('âŒ Fehler beim Hochladen zu OpenAI:', {
      error: err.message,
      errorType: err.type || 'unknown',
      statusCode: err.status || 'N/A'
    });
    
    // ğŸš¨ NEU: Spezifische Fehlermeldungen fÃ¼r hÃ¤ufige Probleme
    if (err.message && err.message.includes('unsafe')) {
      throw new Error('OpenAI hat die Datei als unsicher eingestuft (Moderation API). Bitte Ã¼berprÃ¼fe die Training-Daten auf problematische Inhalte.');
    }
    if (err.message && err.message.includes('invalid')) {
      throw new Error('OpenAI hat die Datei als ungÃ¼ltig eingestuft. Bitte Ã¼berprÃ¼fe das JSONL-Format.');
    }
    
    throw err;
  } finally {
    // LÃ¶sche temporÃ¤re Datei
    if (fs.existsSync(tempPath)) {
      fs.unlinkSync(tempPath);
    }
  }
}

// Starte Fine-Tuning-Job
// WICHTIG: gpt-4o-mini ist NICHT fÃ¼r Fine-Tuning verfÃ¼gbar!
// VerfÃ¼gbare Models: gpt-3.5-turbo, babbage-002, davinci-002
async function startFineTuning(fileId, baseModel = 'gpt-3.5-turbo') {
  const client = getClient();
  if (!client) {
    throw new Error('OpenAI Client nicht verfÃ¼gbar');
  }
  
  try {
    console.log(`ğŸ¯ Starte Fine-Tuning-Job mit Model: ${baseModel}, File-ID: ${fileId}...`);
    
    // Erstelle Fine-Tuning-Job
    const fineTune = await client.fineTuning.jobs.create({
      training_file: fileId,
      model: baseModel,
      hyperparameters: {
        n_epochs: 3 // 3 Epochen fÃ¼r gutes Lernen
      }
    });
    
    console.log(`âœ… Fine-Tuning-Job erfolgreich gestartet!`);
    console.log(`   Job-ID: ${fineTune.id}`);
    console.log(`   Status: ${fineTune.status}`);
    console.log(`   Model: ${baseModel}`);
    console.log(`   ğŸ”— Siehe Details: https://platform.openai.com/finetune`);
    
    return fineTune.id;
  } catch (err) {
    console.error('âŒ Fehler beim Starten des Fine-Tuning-Jobs:', {
      error: err.message,
      errorType: err.type || 'unknown',
      statusCode: err.status || 'N/A',
      fileId
    });
    
    // ğŸš¨ NEU: Spezifische Fehlermeldungen fÃ¼r hÃ¤ufige Probleme
    if (err.message && err.message.includes('unsafe')) {
      throw new Error('OpenAI hat die Training-Datei als unsicher eingestuft (Moderation API). Die Datei enthÃ¤lt zu viele problematische Inhalte. Bitte Ã¼berprÃ¼fe die gefilterten Beispiele im Dashboard.');
    }
    if (err.message && err.message.includes('invalid')) {
      throw new Error('OpenAI hat die Training-Datei als ungÃ¼ltig eingestuft. Bitte Ã¼berprÃ¼fe das JSONL-Format und die Datenstruktur.');
    }
    if (err.message && err.message.includes('not available')) {
      throw new Error(`Das Model "${baseModel}" ist nicht fÃ¼r Fine-Tuning verfÃ¼gbar. VerfÃ¼gbare Models: gpt-3.5-turbo, babbage-002, davinci-002`);
    }
    
    throw err;
  }
}

// PrÃ¼fe Fine-Tuning-Status
async function checkFineTuningStatus(jobId) {
  const client = getClient();
  if (!client) {
    throw new Error('OpenAI Client nicht verfÃ¼gbar');
  }
  
  try {
    const job = await client.fineTuning.jobs.retrieve(jobId);
    
    // ğŸš¨ NEU: Detaillierte Fehler-Logging
    if (job.error) {
      console.error('âŒ Fine-Tuning-Job Fehler:', {
        jobId: job.id,
        status: job.status,
        error: job.error,
        errorMessage: job.error.message || 'Unbekannter Fehler',
        errorCode: job.error.code || 'N/A'
      });
    }
    
    return {
      status: job.status, // 'validating_files', 'queued', 'running', 'succeeded', 'failed', 'cancelled'
      modelId: job.fine_tuned_model || null, // null bis succeeded
      error: job.error ? (job.error.message || JSON.stringify(job.error)) : null,
      errorDetails: job.error || null
    };
  } catch (err) {
    console.error('âŒ Fehler beim PrÃ¼fen des Fine-Tuning-Status:', {
      jobId,
      error: err.message,
      stack: err.stack
    });
    return {
      status: 'error',
      modelId: null,
      error: err.message
    };
  }
}

// ğŸš¨ NEU: Liste alle Fine-Tuning-Jobs von OpenAI
async function listFineTuningJobs(limit = 10) {
  const client = getClient();
  if (!client) {
    throw new Error('OpenAI Client nicht verfÃ¼gbar');
  }
  
  try {
    const jobs = await client.fineTuning.jobs.list({ limit });
    return jobs.data.map(job => ({
      id: job.id,
      status: job.status,
      model: job.model,
      fineTunedModel: job.fine_tuned_model,
      createdAt: job.created_at,
      finishedAt: job.finished_at,
      error: job.error ? {
        message: job.error.message,
        code: job.error.code,
        param: job.error.param
      } : null
    }));
  } catch (err) {
    console.error('âŒ Fehler beim Abrufen der Fine-Tuning-Jobs:', err.message);
    throw err;
  }
}

// ğŸš¨ğŸš¨ğŸš¨ ÃœBERARBEITET: Erstelle System-Prompt - GENAU wie im aktuellen Inference! ğŸš¨ğŸš¨ğŸš¨
async function buildSystemPrompt() {
  const rules = await getRules();
  const config = await getFineTuningConfig();
  
  // ğŸš¨ NEU: System-Prompt wie im aktuellen Inference (multi-agent.js)
  let systemPrompt = `Du bist ein Chat-Moderator auf einer Dating-Plattform. Du verwaltest verschiedene Fake-Profile und antwortest als diese Profile auf Kunden-Nachrichten.

HARTE REGELN (NIEMALS verletzen):
1. KEINE Treffen zustimmen (immer ablehnen, hÃ¶flich ausweichen)
2. KEINE verbotenen WÃ¶rter verwenden
3. PrÃ¤gnant und natÃ¼rlich: 120-250 Zeichen (bei Erstnachrichten 150-300 Zeichen)
4. NatÃ¼rlich und authentisch (nicht nach KI klingen)
5. Schreibe NIEMALS das Zeichen "ÃŸ" â€“ immer "ss" verwenden
6. ğŸš¨ğŸš¨ğŸš¨ ABSOLUT VERBOTEN - KEINE Meta-Kommentare oder bewertenden Einstiegs-Phrasen! ğŸš¨ğŸš¨ğŸš¨
   VERBOTEN: "Das klingt...", "Das klingt so...", "Das klingt nach...", "Es klingt...", "Klingt..."
   VERBOTEN: "Ich verstehe, dass...", "Ich finde es toll/gut/schÃ¶n/super, dass..."
   VERBOTEN: "Ich stelle mir vor...", "Ich stelle mir gerade vor...", "Ich kann mir vorstellen..."
   VERBOTEN: "Das ist spannend/interessant/aufregend..." (als Einstieg)
   VERBOTEN: Jede Formulierung, die die NACHRICHT oder SITUATION des Kunden kommentiert oder bewertet!
   âœ… ERLAUBT STATTDESSEN: Direkt auf den INHALT eingehen, GefÃ¼hle zeigen, Fragen stellen, eigene Gedanken teilen

STIL:
- Sei warmherzig, interessiert, menschlich
- ğŸš¨ğŸš¨ğŸš¨ KRITISCH: Stelle IMMER eine Frage am Ende jeder Nachricht! ğŸš¨ğŸš¨ğŸš¨
- ğŸš¨ğŸš¨ğŸš¨ Die Frage muss zum aktuellen Thema passen und es vertiefen oder erweitern! ğŸš¨ğŸš¨ğŸš¨
- ğŸš¨ğŸš¨ğŸš¨ KEINE generischen Fragen wie "Was magst du?" - stelle spezifische, themenbezogene Fragen! ğŸš¨ğŸš¨ğŸš¨
- Gehe auf alle Anfragen/Themen ein
- Zeige Eigeninitiative (nenne eigene Vorlieben/Interessen, dann frage)
- Sei prÃ¤gnant - keine unnÃ¶tigen Details oder ErklÃ¤rungen (120-250 Zeichen, damit Platz fÃ¼r Frage bleibt)
- Schreibe wie echte Chat-Replies: kurz, natÃ¼rlich, locker, direkt, roh, spontan
- KEINE mechanischen oder generischen Fragen
- KEINE Meta-Kommentare
- KEINE bewertenden Einstiegs-Phrasen`;

  // ğŸš¨ ENTFERNT: Verbotene/Bevorzugte WÃ¶rter im System-Prompt (zu lang, nicht nÃ¶tig)
  // Situationen werden dynamisch in convertToJSONL hinzugefÃ¼gt!
  
  return systemPrompt;
}

// Helper: Lade Regeln (kopiert aus dashboard.js)
async function getRules() {
  const githubClient = getGitHubClient();
  if (githubClient) {
    try {
      const repo = getRepoInfo();
      const possiblePaths = [
        'server/src/config/rules.json',
        'src/config/rules.json',
        'config/rules.json',
        'server/config/rules.json'
      ];
      
      for (const filePath of possiblePaths) {
        try {
          const response = await githubClient.repos.getContent({
            owner: repo.owner,
            repo: repo.repo,
            path: filePath,
            ref: repo.branch
          });
          if (response.data && response.data.content) {
            const content = Buffer.from(response.data.content, 'base64').toString('utf8');
            return JSON.parse(content);
          }
        } catch (err) {
          if (err.status !== 404) throw err;
        }
      }
    } catch (err) {
      if (err.status !== 404) {
        console.error('âš ï¸ Fehler beim Laden von GitHub:', err.message);
      }
    }
  }
  
  // Fallback: Lade von lokaler Datei
  const rulesPath = path.join(__dirname, '../../config/rules.json');
  try {
    if (fs.existsSync(rulesPath)) {
      const data = fs.readFileSync(rulesPath, 'utf8');
      return JSON.parse(data);
    }
  } catch (err) {
    console.error('Fehler beim Laden der Regeln:', err);
  }
  
  return {
    forbiddenWords: [],
    preferredWords: [],
    generalRules: "",
    situationalResponses: {}
  };
}

module.exports = {
  collectPerfectExamples,
  convertToJSONL,
  uploadToOpenAI,
  startFineTuning,
  checkFineTuningStatus,
  listFineTuningJobs,
  getFineTuningConfig,
  saveFineTuningConfig,
  buildSystemPrompt,
  filterWithModeration: filterWithModeration, // Explizit zugewiesen, um sicherzustellen dass es exportiert wird
  checkModeration: checkModeration
};
